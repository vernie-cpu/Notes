# 微服务架构

微服务架构（Microservice Architecture）是一种架构概念，旨在通过将功能分解到各个离散的服务中以实现对解决方案的解耦。

理解微服务架构的爽文：https://www.zhihu.com/question/65502802



## 概念及定义

**概念：**把一个大型的单体应用程序和服务拆分为数个甚至数十个的微服务，它可独立扩展单个组件而不影响整个的应用程序堆栈。

**定义：**围绕业务领域组件来创建应用，这些应用可独立地进行开发、管理和迭代。在分散的组件中使用云架构和平台式部署、管理和服务，使产品交付变得更加简单。

**本质：**用一些功能比较明确、业务比较精练的服务去解决更大、更实际的问题。



## 优点和缺点

### 优点

> **关键点：**复杂度可控，独立按需扩展，技术选型灵活，容错、可用性高

1. 它解决了复杂性的问题。它会将一种怪异的整体应用程序分解成一组服务。虽然功能总量不变，但应用程序已分解为可管理的块或服务。每个服务都以RPC或消息驱动的API的形式定义了一个明确的边界；Microservice架构模式实现了一个模块化水平。

2. 这种架构使每个服务都能够由专注于该服务的团队独立开发。开发人员可以自由选择任何有用的技术，只要该服务符合API合同。当然，大多数组织都希望避免完全无政府状态并限制技术选择。然而，这种自由意味着开发人员不再有义务使用在新项目开始时存在的可能过时的技术。在编写新服务时，他们可以选择使用当前的技术。此外，由于服务相对较小，因此使用当前技术重写旧服务变得可行。

3. Microservice架构模式使每个微服务都能独立部署。开发人员不需要协调部署本地服务的变更。这些变化可以在测试后尽快部署。例如，UI团队可以执行A/B测试，并快速迭代UI更改。Microservice架构模式使连续部署成为可能。

   > AB测试是为 Web 或 App 界面或流程制作两个（A/B）或多个（A/B/n）版本，在同一时间维度，分别让组成成分相同（相似）的访客群组（目标人群）随机的访问这些版本，收集各群组的用户体验数据和业务数据，最后分析、评估出最好版本，正式采用。

4. Microservice架构模式使每个服务都可以独立调整。您可以仅部署满足其容量和可用性限制的每个服务的实例数。此外，您可以使用最符合服务资源要求的硬件。



### 缺点

> **关键点（挑战）：**多服务运维难度增加，系统部署依赖，服务间通信成本，数据一致性，系统集成测试，稳定性降低，问题定位难度增加等。
>
> 数据一致性往往是需要研发同学重点关注的对象，微服务架构下的分布式事务是带来数据一致性问题的关键，当前主流的分布式事务解决方案：https://zhuanlan.zhihu.com/p/183753774

1. 微服务架构整个应用分散成多个服务，定位故障点非常困难。
2. 稳定性下降。服务数量变多导致其中一个服务出现故障的概率增大，并且一个服务故障可能导致整个系统挂掉。事实上，在大访问量的生产场景下，故障总是会出现的。
3. 服务数量非常多，部署、管理的工作量很大。
4. 开发方面，如何保证各个服务在持续开发的情况下仍然保持协同合作和分布式场景下的数据一致性。
5. 测试方面，服务拆分后，几乎所有功能都会涉及多个服务。原本单个程序的测试变为服务间调用的测试。测试变得更加复杂。



**为了提高架构的健壮性，解决以上微服务架构带来的挑战，从两方面着手解决。**

- **一方面尽量减少故障发生的概率**

  - **监控 - 发现故障的征兆**：在高并发分布式的场景下，故障经常是突然间就雪崩式爆发。所以必须建立完善的监控体系，尽可能发现故障的征兆。

  - **定位问题 - 链路跟踪**：在微服务架构下，一个用户的请求往往涉及多个内部服务调用。为了方便定位问题，需要能够记录每个用户请求时，微服务内部产生了多少服务调用，及其调用关系。这个叫做链路跟踪。

  - **分析问题 - 日志分析**：在应用规模变大时，我们需要一个日志的“**搜索引擎**”。以便于能准确的找到想要的日志。另外，数据源一侧还需要收集日志的组件和展示结果的UI组件。

  - **网关 - 权限控制、服务治理**：拆分成微服务后，出现大量的服务，大量的接口，使得整个调用关系乱糟糟的。为了应对这些情况，微服务的调用需要一个把关的东西，也就是网关。在调用者和被调用者中间加一层网关，每次调用时进行权限校验。另外，网关也可以作为一个提供服务接口文档的平台。

    

- **一方面降低故障造成的影响**

  - **服务注册与发现 - 动态扩容**：根据服务功能、时间段的不同，需要不同数量的实例。一般来说，一个服务都会部署多个实例，这样一来能够分担压力提高性能，二来即使一个实例挂了其他实例还能响应。
  - **熔断、服务降级、限流**
    - **熔断**：当一个服务因为各种原因停止响应时，调用方通常会等待一段时间，然后超时或者收到错误返回。如果调用链路比较长，可能会导致请求堆积，整条链路占用大量资源一直在等待下游响应。所以当多次访问一个服务失败时，应熔断，标记该服务已停止工作，直接返回错误。直至该服务恢复正常后再重新建立连接。
    - **服务降级**：当下游服务停止工作后，如果该服务并非核心业务，则上游服务应该降级，以保证核心业务不中断。比如网上超市下单界面有一个推荐商品凑单的功能，当推荐模块挂了后，下单功不能一起挂掉，只需要暂时关闭推荐功能即可。
    - **限流**：限流策略有很多，最简单的比如当单位时间内请求数过多时，丢弃多余的请求。另外，也可以考虑分区限流。仅拒绝来自产生大量请求的服务的请求。例如商品服务和订单服务都需要访问促销服务，商品服务由于代码问题发起了大量请求，促销服务则只限制来自商品服务的请求，来自订单服务的请求则正常响应。



## 服务间的层级关系

<img src="images/microserver_framework.png">



# RPC 和 gRPC 

## **RPC**

**RPC(remote procedure call 远程过程调用)框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从server/client模型。使用的时候客户端调用server端提供的接口就像是调用本地的函数一样。**

**RPC是一种设计、实现框架，通讯协议只是其中一部分。**它和http协议不是对立的，http协议本身就可以作为RPC框架的传输协议。同时，只要能通过某种方式实现远程过程调用的都可以叫RPC，这本身和http没啥关系。

**RPC的本质是提供了一种轻量无感知的跨进程通信的方式**，在分布式机器上调用其他方法与本地调用无异（远程调用的过程是透明的，你并不知道这个调用的方法是部署在哪里，通过PRC能够解耦服务）。RPC是根据语言的API来定义的，而不是基于网络的应用来定义的，调用更方便，协议私密更安全、内容更小、效率更高。

**典型的RPC模型：**

<img src='./images/RPC.png' style='width: 60%; float: left'>

**为什么需要RPC？**

http接口是在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段。优点就是简单、直接、开发方便，现成的http协议进行传输。

但是如果是一个大型的网站，内部子系统较多、接口非常多的情况下，RPC框架的好处就显示出来了。

- 首先（基于TCP协议的情况下）就是长链接，减少了网络开销；
- 其次就是RPC框架一般都有注册中心，有丰富的监控管理。发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作
- 第三就是安全性。
- 最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑。



**实现RPC需要解决的三个问题：**

- 建立通信：

  在客户端与服务端建立起数据传输通道，大都是TCP连接（gRPC使用了HTTP2）。

- 寻址：

  A服务器上的应用需要告诉RPC框架：B服务器地址、端口，调用函数名称。所以必须实现待调用方法到call ID的映射。

- 序列化与反序列化：

  由于网络协议都是二进制的，所以调用方法的参数在进行传递时首先要序列化成二进制，B服务器收到请求后要再对参数进行反序列化。恢复为内存中的表达方式，找到对应的方法进行本地调用，得到返回值。返回值从B到A的传输仍要经过序列化与反序列化的过程。



## **gRPC**

> A high-performance, open-source universal RPC framework
>
> 一个开源、高性能的通用 RPC 框架

gRPC是谷歌开源的一个 RPC 框架，面向移动和 HTTP2.0 设计，带来诸如双向流、流控、头部压缩、单TCP连接上的多路复用等特性。



**gRPC vs Restful API**

既然是server/client模型，那么我们直接用restful api不是也可以满足吗，为什么还需要RPC呢？

gRPC和restful API都提供了一套通信机制，用于server/client模型通信，而且它们都使用http作为底层的传输协议（gRPC使用的http2.0，而restful api则不确定，根据需要选择合适的协议）。但是 gRPC 还有下面一些独特的优势：

- 严格的接口约束。gRPC通过protobuf来定义接口，有更加严格的接口约束条件。
- 高性能。通过protobuf可以将数据序列化为二进制编码，大幅减少传输的数据量，从而大幅提高性能。
- 高安全性。gRPC 框架远程调用服务器的方法，就像在本地调用一样，把很多网络请求的细节都透明化。



**gRPC主要有4种请求／响应模式，分别是：**

- 简单模式（Simple RPC）

  客户端发起一次请求，服务端响应一个数据，即标准RPC通信。

- 服务端数据流模式（Server-side streaming RPC）

  这种模式是客户端发起一次请求，服务端返回一段连续的数据流。典型的例子是客户端向服务端发送一个股票代码，服务端就把该股票的实时数据源源不断的返回给客户端。

- 客户端数据流模式（Client-side streaming RPC）

  与服务端数据流模式相反，这次是客户端源源不断的向服务端发送数据流，而在发送结束后，由服务端返回一个响应。典型的例子是物联网终端向服务器报送数据。

- 双向数据流模式（Bidirectional streaming RPC）

  这是客户端和服务端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，也就是可以实现实时交互。比如聊天应用。
  
  

### Protobuf

> Protobuf实际是一套类似Json或者XML的数据传输格式和规范，在不同应用或进程之间进行通信时使用。通信时所传递的信息先通过Protobuf定义的message数据结构进行打包，然后再编译成二进制的码流再进行传输或者存储。
>
> ProtoBuf 具有强大的IDL（interface description language，接口描述语言）和相关工具集（主要是protoc）。用户写好.proto描述文件后，protoc可以将其编译成众多语言的接口代码。

**优点：**

- 足够简单
- 序列化后体积很小：消息大小只需要XML的1/10 ~ 1/3
- 解析速度快：解析速度比XML快20 ~ 100倍
- 多语言支持
- 更好的兼容性，Protobuf设计的一个原则就是要能够很好的支持向下或向上兼容



### 搭建 gRPC 实例

> 示例基于官方文档演示。
>
> https://grpc.io/docs/languages/python/quickstart/

gRPC的使用通常包括如下几个步骤：

1. 通过protobuf来定义接口和数据类型
2. 编写gRPC server端代码
3. 编写gRPC client端代码



**目录结构**

```shell
| -- grpc_test
| -- protos
	| -- greet.proto
| -- packges
	| -- __init__.py
	| -- greet_pb2.py
	| -- greet_pb2_grpc.py
| -- greet_server.py
| -- greet_client.py
```



**安装grpc库**

```shell
# 安装grpc
python -m pip3 install grpcio

# 安装grpc工具库
python -m pip3 install grpcio-tools
```



**编写 .proto 文件**

> Proto 语法：https://www.jianshu.com/p/da7ed5914088

```protobuf
// 指定proto语法版本
syntax = "proto3";

package packages;

// 定义服务
service GreetService {
  // 定义借口和数据类型
  rpc sayHello(helloRequest) returns (helloResponse) {}
}

// 定义请求数据类型
message helloRequest {
  string name = 1;
}

// 定义响应数据类型
message helloResponse {
  string msg = 1;
}
```



**将 .proto 文件生成对应的 py 文件**

目录结构中的`greet_pb2.py`和`greet_pb2_grpc.py`就是通过 grpc_tools 生成的。在 packges 目录下执行如下命令：

```shell
python -m grpc_tools.protoc -I../protos --python_out=. --grpc_python_out=. ../protos/greet.proto
```



**编写server.py**

```python
import time
from concurrent import futures

import grpc

from packages.greet_pb2 import helloResponse
from packages.greet_pb2_grpc import add_GreetServiceServicer_to_server, GreetServiceServicer


class Hello(GreetServiceServicer):
    # 实现接口
    def sayHello(self, request, context):
        print(f'{request.name} is coming')
        return helloResponse(msg='hello, %s' % request.name)


def serve():
    # 这里通过thread pool来并发处理server的任务
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))

    # 将对应的任务处理函数添加到rpc server中
    add_GreetServiceServicer_to_server(Hello(), server)

    # 这里使用的非安全接口，gRPC支持TLS/SSL安全连接，以及各种鉴权机制
    server.add_insecure_port('[::]:50000')
    server.start()

    try:
        while True:
            time.sleep(60 * 60)
    except KeyboardInterrupt:
        pass


if __name__ == '__main__':
    serve()
```



**编写client.py**

```python
import grpc

from packages.greet_pb2 import helloRequest
from packages.greet_pb2_grpc import GreetServiceStub


def run():
    # 使用上下文管理，自动关闭链接
    with grpc.insecure_channel('localhost:50000') as channel:
        # 客户端通过 stub 来实现 rpc 通信
        stub = GreetServiceStub(channel)
        # 调用服务端接口
        res = stub.sayHello(helloRequest(name='zhangjian'))

    print('server message:', res.msg)


if __name__ == '__main__':
    run()
```
